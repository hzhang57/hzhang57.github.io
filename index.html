<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta content="IE=7.0000" http-equiv="X-UA-Compatible">
<title>Hao Zhang's Homepage</title>
<meta name="description" content="Hao Zhang, 张浩, Senior Research Scientist in Agency for Science, Technology and Research, Singapore (A*STAR). visual abductive reasoning, video QA, video understanding, atomic visual action detection, semantical concept indexing, multimedia event detection.">
<meta name="keywords" content="Hao Zhang, 张浩, City Uninversity of Hong Kong, A*STAR, video QA, visual abductive reasoning, video classification">

<link rel="stylesheet" type="text/css" href="./files/zhanghao.css">
<!-- <script type="text/javascript" async="" src="./files/ga.js"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39532305-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script> -->

<style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}
</style></head>
<body>
<div id="content">

<div id="news">
<h2>News</h2><br>
<font size="3px">

<b>17 April 2024</b><br>
<span class="easylink">
One paper is accepted by <a href="https://ijcai24.org/", target="_blank"> International Joint Conference on Artificial Intelligence (IJCAI 2024)</a> on Point Cloud Understanding with Vision Foundational Models. 
</span><br><br>

<b>30 June 2022</b><br>
<span class="easylink">
Four papers are accepted by <a href="https://2022.acmmm.org/", target="_blank">ACM Multimedia (ACM MM 2023)</a> on Video Recognition and Retrieval. 
</span><br><br>

<b>3 Mar 2022</b><br>
<span class="easylink">
1 paper is accepted by <a href="https://cvpr2022.thecvf.com/", target="_blank">Computer Vision and Pattern Recognition (CVPR 2022)</a> on Efficient Video Recognition. 
</span><br><br>

<b>5 July 2021</b><br>
<span class="easylink">
2 papers are accepted by <a href="https://2021.acmmm.org/", target="_blank">ACM Multimedia (ACM MM 2021)</a> on Efficient Video Recognition and Retrieval. 

</span><br><br>

<b>29 July 2020</b><br>
<span class="easylink">
Rank <a href="./award/Track-4-3rd.pdf", target="_blank">3rd</a> in <a href="https://2020.acmmm.org/", target="_blank">ACM Multimedia (ACM MM workshop HiEVE 2020)</a> on Human-Centric Video Analysis. 

</span><br><br>

<b>29 July 2020</b><br>
<span class="easylink">
1 paper is accepted by <a href="https://2020.acmmm.org/", target="_blank">ACM Multimedia (ACM MM 2020)</a> on Sport Analysis. 

</span><br><br>

<b>21 December 2018</b><br>
<span class="easylink">
1 paper is accepted by <a href="https://2020.acmmm.org/", target="_blank">IEEE Trans Multimedia (TMM 2018)</a> on Multimedia Event Detection. 

</span><br><br>
</div>
<div id="left">
<table style="background-color:white;">
<tbody><tr nosave="">
<td valign="CENTER">
<img src="./files/zhanghao.jpeg" height="250" align="left">
</td>

<td valign="CENTER" width="2%">
</td>

<td valign="CENTER" halign="LEFT">
<font size="+0">
<b><font size="+2">Hao ZHANG&nbsp;</font></b>
<p style="margin-left:0px;">
<img src="./files/name.png", height="60">
</p><p style="margin-left:0px;">
<b>Senior Research Scientist</b>
</p><p style="margin-left:0px;">
<a href="https://www.a-star.edu.sg/ihpc", target="_blank">Institute of High Performance Computing</a><br/>
<a href="https://www.a-star.edu.sg/", target="_blank">Agency for Science, Technology and Research (A*STAR)</a><br/>
</p><p style="margin-left:0px;">
  1 Fusionopolis Way, #20-10, Connexis North Tower, Singapore 138632<br>
</p><p style="margin-left:0px;">
Email:  zhanghaoinf AT gmail DOT com</a><br>
</p></font><p><font size="+0">
</font>
</p></td>
</tr>
</tbody></table>

<div class="box">
I work as Senior Research Scientist in IHPC, Agency for Science Technology and Research (A*STAR). My research interests lies in visual abductive reasoning, video understanding, and multimedia event detection. I have around 20 publications in top-tier journals/conferences including CVPR, IJCAI, ACM Multimedia, IEEE Trans Multimedia. I also serves as a technical program committee (TPC) member for ACM Multimedia 2019/2020, and reviewer for ACM Multimedia 2021/2024, CVPR2021/2022, ICCV2021, ECCV2022/2024, IEEE TCSVT, IEEE TCDS, ACM TOMM, Neurocomputing, ICCV 2019 Workshop, ICME 2020, 《中国科学: 信息科学》.</br>

</div>

<h2 style="CLEAR: both;">Education</h2>
<table>
  <tbody>
  <tr>
    <td><span class="title">City Univeristy of Hong Kong (CityU-HK)</span> <br>
  Ph.D. in Computer Science &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Sept. 2013 - Feb. 2018, Hong Kong, China <br>
  Advisor: <a href="https://scholars.cityu.edu.hk/en/persons/chong-wah-ngo(340b6e9c-7062-4cf6-8996-a7aa0fcd6c61).html" target="_blank">Prof. Chong-Wah Ngo</a>
     </td></tr></tbody></table>
<table>
  <tbody>
  <tr>
    <td><span class="title">Chinese University of Hong Kong (CUHK)</span> <br>
  Master in Computer Science &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Sept. 2012 - Jun. 2013, Hong Kong, China <br>
     </td></tr></tbody></table>
<table>
  <tbody>
  <tr>
    <td><span class="title">Nanjing University (NJU)</span> <br>
  Bachelor in Electronics Engineering &nbsp;&nbsp;&nbsp;&nbsp;  Sept. 2008 - Jun. 2012, Nanjing, China <br>
     </td></tr></tbody></table>

<h2 style="CLEAR: both">Experiences</h2>
<table>
  <tbody><tr>
    <td> <span class="title">Senior Research Scientist</span>, Agency for Science, Technology and Research (A*STAR), Sept. 2021 - Present <br>
    </td></tr></tbody>
</table>
<table>
  <tbody><tr>
    <td> <span class="title">Research Scientist</span>, Singapore Management University, Oct. 2019 - Jun. 2021 <br>
      Advisior: <a href="https://faculty.smu.edu.sg/profile/ngo-chong-wah-601" target="_blank">Chong-Wah Ngo</a>
    </td></tr></tbody>
</table>
<table>
  <tbody><tr>
    <td> <span class="title">Senior Algorithm Engineer</span>, Alibaba DAMO Academy, Mar. 2018 - Jul. 2019   <br>
    </td></tr></tbody>
</table>
<div id="papers">
<h2>Selected Publications</h2> (Full list see my [<A href="https://scholar.google.com.hk/citations?user=Cqy13vYAAAAJ&hl=zh-CN">Google Scholar<A>] *Corresponding ) 
</br>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">PointTFA: Training-Free Clustering Adaption of Large 3D Point Cloud Models</span> 
      <br>Jinmeng Wu, Chong Cao, <b>Hao Zhang</b>*, Basura Fernando, Yanbin Hao, Hanyu Hong<br>
      International Joint Conference on Artificial Intelligence (IJCAI, 2024, <font color="red">CCF-A</font>) &nbsp;&nbsp; <a href="https://github.com/CaoChong-git/PointTFA" target="_blank">Codes</a> &nbsp;&nbsp;
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2303.10428" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">A Region-Prompted Adapter Tuning for Visual Abductive Reasoning</span> 
      <br><b>Hao Zhang</b>*, Yeo Keat Ee, Basura Fernando<br>
      Arxiv, 2023 &nbsp;&nbsp; <a href="" target="_blank">Codes</a> &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2207.05526" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Long-term Leap Attention, Short-term Periodic Shift for Video Classification</span> 
      <br><b>Hao Zhang</b>, Lechao Cheng, Yanbin Hao*, Chong-Wah Ngo<br>
      ACM Multimedia (ACM MM, 2022, Oral, <font color="red">CCF-A</font>) &nbsp;&nbsp; <a href="https://github.com/VideoNetworks/LAPS-transformer" target="_blank">Codes</a> &nbsp;&nbsp;
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2203.09694" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Group Contextualization for Video Recognition</span> 
      <br>Yanbin Hao, <b>Hao Zhang</b>*, Chong-Wah Ngo, Xiangnan He<br>
      Computer Vision and Pattern Recognition (CVPR, 2022, <font color="red">CCF-A</font>) &nbsp;&nbsp; <a href="https://github.com/haoyanbin918/Group-Contextualization" target="_blank">Codes</a> &nbsp;&nbsp;
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="http://staff.ustc.edu.cn/~hexn/papers/mm22-video-hashing.pdf" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Unsupervised Video Hashing with Multi-granularity Contextualization and Multi-structure Preservation</span> 
      <br>Yanbin Hao, Jingru Duan, <b>Hao Zhang</b>*, Bin Zhu, Pengyuan Zhou, Xiangnan He<br>
      ACM Multimedia (ACM MM, 2022, <font color="red">CCF-A</font>) &nbsp;&nbsp; <a href="https://github.com/haoyanbin918/MCMSH" target="_blank">Codes</a> &nbsp;&nbsp;
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="http://staff.ustc.edu.cn/~hexn/papers/mm22-hourglass-cnn-video.pdf" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Hierarchical Hourglass Convolutional Network for Efficient Video Classification</span> 
      <br>Yi Tan, Yanbin Hao, <b>Hao Zhang</b>, Shuo Wang, Xiangnan He<br>
      ACM Multimedia (ACM MM, 2022, <font color="red">CCF-A</font>) &nbsp;&nbsp; <a href="https://github.com/ty-97/H2CN" target="_blank">Codes</a> &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2207.07284" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Parameterization of Cross-token Relations with Relative Positional Encoding for Vision MLP</span> 
      <br>Zhicai Wang, Yanbin Hao, Xingyu Gao, <b>Hao Zhang</b>, Shuo Wang, Tingting Mu, Xiangnan He<br>
      ACM Multimedia (ACM MM, 2022, <font color="red">CCF-A</font>) &nbsp;&nbsp; <a href="https://github.com/Zhicaiwww/PosMLP" target="_blank">Codes</a> &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2108.02432" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Token Shift Transformer for Video Classification</span> 
      <br><b>Hao Zhang</b>, Yanbin Hao*, Chong-Wah Ngo<br>
      ACM Multimedia (ACM MM, 2021, <font color="red">CCF-A</font>) &nbsp;&nbsp; <a href="https://github.com/VideoNetworks/TokShift-Transformer" target="_blank">Codes</a> &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475241" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Fine-grained Cross-modal Alignment Network for Text-Video Retrieval</span> 
      <br>Ning Han, Jingjing Chen, Gruangyi Xiao, <b>Hao Zhang</b>, Yawen Zeng, Hao Chen<br>
      ACM Multimedia (ACM MM, 2021, Oral, <font color="red">CCF-A</font>) &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://ink.library.smu.edu.sg/context/sis_research/article/7486/viewcontent/3394171.3413595.pdf" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification</span> 
      <br>Yanbin Hao, <b>Hao Zhang</b>*, Chong-Wah Ngo, Qiang Liu, Xiaojun Hu<br>
      ACM Multimedia (ACM MM, 2020, Oral, <font color="red">CCF-A</font>) &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://ieeexplore.ieee.org/document/8556097" target="_blank"><img src="./files/pdf.gif"><br>pdf</a></td>
    <td><span class="title">A Fine Granularity Object-level Representation for Event Detection and Recounting</span> 
      <br><b>Hao Zhang</b>, Chong-Wah Ngo<br>
      IEEE. Trans on Multimedia (IEEE TMM, 2018, <font color="red">JCR-1</font>) &nbsp;&nbsp; &nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<h2 style="CLEAR: both;">Professional Services</h2>

<table><tbody><tr><td>
  <span class="title">Reviewer of Conferences</span>: <br>
  <b>2024</b>: ECCV, ACM Multimedia, BMVC, AAAI (Program Committee Member) <br>
  <b>2023</b>: ACM Multimedia, ACM Trans TOMM, BMVC, ICME <br>
  <b>2022</b>: CVPR, ICCV, ECCV, ICME, Neurocomputing, Pattern Recognition, IEEE TMM, ACM Trans TOMM <br>
  <b>2021</b>: ACM Multimedia <br>
  <b>2020</b>: ACM Multimedia (Technical Program Committee member) <br>
  <b>2029</b>: ACM Multimedia (Technical Program Committee member) <br>
</td></tr></tbody></table>




		
<h2 style="CLEAR: both;">Useful Links</h2>
<table><tbody>
  <tr><td> <span class="title"><a href="./https://www.cityu.edu.hk/ceng/about-us/our-rankings" target="_blank">City University of Hong Kong CS Conference Rankings</a></span> </td></tr>
</tbody></table>

</br>

<div id="clustrmaps-widget"></div> <a href="https://clustrmaps.com/site/1bzqn"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=_AJAKwJ4Dy9dR8UfY0msCFRoPHCvgznC2_w_BTi5kzQ&cl=ffffff" /></a>

<p>Last update: 26 March, 2024. Webpage template borrows from <a href="http://wnzhang.net/">Weinan Zhang</a>.</p>

</div>
</div>


</body></html>
